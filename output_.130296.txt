MASTER_ADDR: gpu-55
CUDA_VISIBLE_DEVICES=0,1,2,3
Fri Aug 15 09:09:23 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   26C    P0             50W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   26C    P0             50W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-40GB          On  |   00000000:81:00.0 Off |                    0 |
| N/A   24C    P0             51W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |
| N/A   24C    P0             49W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
torch: 2.5.1+cu121 cuda: 12.1 cuda available: True
08-15 09:09:34 I initializing rank=2 local_rank=2 nodes=1 hostname=gpu-55 master_addr=gpu-55 master_port=55555 (waiting for all 4 processes to connect)
08-15 09:09:34 I initializing rank=1 local_rank=1 nodes=1 hostname=gpu-55 master_addr=gpu-55 master_port=55555 (waiting for all 4 processes to connect)
08-15 09:09:34 I initializing rank=0 local_rank=0 nodes=1 hostname=gpu-55 master_addr=gpu-55 master_port=55555 (waiting for all 4 processes to connect)
08-15 09:09:34 I initializing rank=3 local_rank=3 nodes=1 hostname=gpu-55 master_addr=gpu-55 master_port=55555 (waiting for all 4 processes to connect)
[rank3]:[W815 09:09:35.516367252 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W815 09:09:35.752434565 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank0]:[W815 09:09:35.921531241 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W815 09:09:35.921666979 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
08-15 09:09:36 I initialized process rank=2 local_rank=2 pid=61958
08-15 09:09:36 I initialized process rank=3 local_rank=3 pid=61959
08-15 09:09:36 I initialized process rank=1 local_rank=1 pid=61957
08-15 09:09:36 I initialized process rank=0 local_rank=0 pid=61956
08-15 09:09:36 I rank=0 local_rank=0 -> cuda:0 (CUDA_VISIBLE_DEVICES=0)
08-15 09:09:36 I initialized 4 processes
08-15 09:09:36 W disabled cudnn benchmark
08-15 09:09:36 W enabled cudnn deterministic
08-15 09:09:36 I log file: /home/beknur.kalmakhanbet/save/in1k/w1iannhn/log.txt
08-15 09:09:36 I no seed specified -> using seed=0
08-15 09:09:36 I ------------------
08-15 09:09:36 I initializing wandb (mode=disabled)
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
08-15 09:09:36 I ------------------
08-15 09:09:36 I stage_id: w1iannhn
08-15 09:09:36 I python main_train.py --hp src/vislstm/yamls/pretrain/vil/80M_res224finetuning_e5.yaml
08-15 09:09:36 I ------------------
08-15 09:09:36 I VERSION CHECK
08-15 09:09:36 I executable: /home/beknur.kalmakhanbet/miniconda3/envs/minLSTM/bin/python
08-15 09:09:36 I python version: 3.9.21
08-15 09:09:36 I torch version: 2.5.1+cu121
08-15 09:09:36 I torch.cuda version: 12.1
08-15 09:09:36 I torchvision.version: 0.20.1+cu121
08-15 09:09:38 I torchmetrics version: 1.6.2
08-15 09:09:38 I kappaschedules version: 0.0.31
08-15 09:09:38 I kappamodules version: 0.1.76
08-15 09:09:38 I ------------------
08-15 09:09:38 I SYSTEM INFO
08-15 09:09:38 I host name: gpu-55
08-15 09:09:38 I OS: Linux-5.15.161-ql-generic-13.0-14-x86_64-with-glibc2.35
08-15 09:09:38 I OS version: #1 SMP Wed Jun 26 16:19:39 UTC 2024
08-15 09:09:39 I CUDA version: 12.4
08-15 09:09:39 I current commit hash: f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
08-15 09:09:39 I latest git tag: 
08-15 09:09:39 I initialized process rank=0 local_rank=0 pid=61956 hostname=gpu-55
08-15 09:09:39 I initialized process rank=3 local_rank=3 pid=61959 hostname=gpu-55
08-15 09:09:39 I total_cpu_count: 16
08-15 09:09:39 I ------------------
08-15 09:09:39 I STATIC CONFIG
08-15 09:09:39 I account_name: beknur.kalmakhanbet
08-15 09:09:39 I output_path: /home/beknur.kalmakhanbet/save
08-15 09:09:39 I ------------------
08-15 09:09:39 I CLI ARGS
08-15 09:09:39 I hp: src/vislstm/yamls/pretrain/vil/80M_res224finetuning_e5.yaml
08-15 09:09:39 I accelerator: gpu
08-15 09:09:39 I testrun: False
08-15 09:09:39 I minmodelrun: False
08-15 09:09:39 I mindatarun: False
08-15 09:09:39 I mindurationrun: False
08-15 09:09:39 I static_config_uri: static_config.yaml
08-15 09:09:39 I ------------------
08-15 09:09:39 I DIST CONFIG
08-15 09:09:39 I rank: 0
08-15 09:09:39 I local_rank: 0
08-15 09:09:39 I world_size: 4
08-15 09:09:39 I nodes: 1
08-15 09:09:39 I backend: nccl
08-15 09:09:39 I slurm job id: 130296
08-15 09:09:39 I hostnames: gpu-55
08-15 09:09:39 I ------------------
master_factory_base_path: vislstm
stage_name: in1k
datasets:
  train:
    kind: imagenet1k
    split: train
    sample_wrappers:
    - kind: x_transform_wrapper
      transform:
      - kind: random_resized_crop
        size: 224
        scale:
        - 0.08
        - 1.0
        interpolation: bicubic
      - kind: random_horizontal_flip
      - kind: transforms.three_augment
        blur_sigma:
        - 0.1
        - 2.0
      - kind: color_jitter
        brightness: 0.3
        contrast: 0.3
        saturation: 0.3
        hue: 0.0
      - kind: imagenet1k_norm
    - kind: one_hot_wrapper
    collators:
    - kind: mix_collator
      mixup_alpha: 0.8
      cutmix_alpha: 1.0
      mixup_p: 0.5
      cutmix_p: 0.5
      apply_mode: batch
      lamb_mode: batch
      shuffle_mode: flip
  val:
    kind: imagenet1k
    split: val
    sample_wrappers:
    - kind: x_transform_wrapper
      transform:
      - kind: resize
        size: 224
        interpolation: bicubic
      - kind: center_crop
        size: 224
      - kind: imagenet1k_norm
model:
  initializers:
  - kind: previous_run_initializer
    stage_id: ralia1v1
    stage_name: in1k
    model_name: vislstm
    checkpoint: last
    use_checkpoint_kwargs: true
  optim:
    kind: adamw
    lr: 1.0e-05
    betas:
    - 0.9
    - 0.999
    weight_decay: 0.05
    schedule:
      kind: linear_warmup_cosine_decay_schedule
      warmup_epochs: 1
      end_value: 1.0e-06
    lr_scaler:
      kind: linear_lr_scaler
      divisor: 1024
trainer:
  kind: classification_trainer
  precision: bfloat16
  backup_precision: float16
  max_epochs: 5
  effective_batch_size: 512
  log_every_n_epochs: 1
  callbacks:
  - kind: checkpoint_callback
  - kind: checkpoint_callback
    every_n_epochs: 10
    save_latest_weights: true
    save_latest_optim: true
  - kind: offline_accuracy_callback
    every_n_epochs: 1
    dataset_key: val
08-15 09:09:39 I copied unresolved hp to /home/beknur.kalmakhanbet/save/in1k/w1iannhn/hp_unresolved.yaml
08-15 09:09:39 I dumped resolved hp to /home/beknur.kalmakhanbet/save/in1k/w1iannhn/hp_resolved.yaml
08-15 09:09:39 I ------------------
08-15 09:09:39 I training stage 'in1k'
08-15 09:09:39 I using different seeds per process (seed+rank)
08-15 09:09:39 I set seed to 0
08-15 09:09:39 I ------------------
08-15 09:09:39 I initializing datasets
08-15 09:09:39 I initializing train
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
08-15 09:09:40 I initialized process rank=1 local_rank=1 pid=61957 hostname=gpu-55
fatal: No annotated tags can describe 'f7fdf8a3a79a50d095f5ac53fe1e53af30ab2942'.
However, there were unannotated tags: try --tags.
08-15 09:09:40 I initialized process rank=2 local_rank=2 pid=61958 hostname=gpu-55
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd-gpu-55: error: *** JOB 130296 ON gpu-55 CANCELLED AT 2025-08-15T20:03:43 ***
slurmstepd-gpu-55: error: *** STEP 130296.0 ON gpu-55 CANCELLED AT 2025-08-15T20:03:43 ***
